{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rocky-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sn\n",
    "import datetime\n",
    "import random\n",
    "from datetime import date\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import statistics \n",
    "from statistics import mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_strings_to_dates(dataframe, testset=False):\n",
    "    frame = dataframe.copy()\n",
    "    if testset:\n",
    "        frame.dt = [date.fromisoformat(d) for d in frame.dt]\n",
    "        frame.first_load_date = [date.fromisoformat(d) for d in frame.first_load_date]\n",
    "        frame.ts_signup = [datetime.datetime.strptime(d, '%Y-%m-%d %H:%M:%S+00:00') for d in frame.ts_signup]\n",
    "        frame.ts_signup = [date(year=d.year, month=d.month, day=d.day) for d in frame.ts_signup]\n",
    "    else:\n",
    "        frame.dt = [date.fromisoformat(d) for d in frame.dt]\n",
    "        frame.first_load_date = [date.fromisoformat(d) for d in frame.first_load_date]\n",
    "        frame.most_recent_load_date = [date.fromisoformat(d) for d in frame.most_recent_load_date]\n",
    "        frame.ts_signup = [datetime.datetime.strptime(d, '%Y-%m-%d %H:%M:%S+00:00') for d in frame.ts_signup]\n",
    "        frame.ts_signup = [date(year=d.year, month=d.month, day=d.day) for d in frame.ts_signup]\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "invalid-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_to_int(dataframe, columns):\n",
    "    frame = dataframe.copy()\n",
    "    conversion = lambda dt_time: 10000*dt_time.year + 100*dt_time.month + dt_time.day\n",
    "    \n",
    "    for col in columns:\n",
    "        frame[f'{col}'] = [conversion(d) for d in frame[f'{col}']]\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decreased-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rows_by_driver_id(dataframe):\n",
    "    '''\n",
    "    Returns a new dataframe indexed by Driver ID using an optimal set of aggregations per column.\n",
    "    This method will return a dataframe that only contains the columns listed below.\n",
    "    Note: duplicate columns are inherently pruned (simply by not adding them below), so it is \n",
    "        safe to pass in the full dataframe and expect a pruned version in return. \n",
    "        Also note that the `id_driver` will now be the index of the dataframe and NOT its own column.\n",
    "    '''\n",
    "    minimum = 'min'\n",
    "    maximum = 'max'\n",
    "    median = 'median'\n",
    "    random_mode = lambda x: random.choice(pd.Series.mode(x if isinstance(x, list) else list(x)))\n",
    "    average = lambda x: pd.Series.mean(x)\n",
    "\n",
    "    aggregation = {\n",
    "        'dt': maximum,\n",
    "        'weekday': random_mode,\n",
    "        'dim_carrier_type': random_mode,\n",
    "        'carrier_trucks': mode,\n",
    "        'num_trucks': maximum,\n",
    "        'interested_in_drayage': random_mode,\n",
    "        'port_qualified': random_mode,\n",
    "        'signup_source': random_mode,\n",
    "        'ts_signup': maximum,\n",
    "        'days_signup_to_approval': maximum,\n",
    "        'driver_with_twic': mode,\n",
    "        'dim_preferred_lanes': mode,\n",
    "        'first_load_date': minimum,\n",
    "        'loads': random_mode,\n",
    "        'marketplace_loads_otr': maximum,\n",
    "        'marketplace_loads_atlas': maximum,\n",
    "        'marketplace_loads': maximum,\n",
    "        'brokerage_loads_otr': maximum,\n",
    "        'brokerage_loads_atlas': maximum,\n",
    "        'brokerage_loads': maximum,\n",
    "        'label': random_mode\n",
    "    }\n",
    "\n",
    "    return dataframe.groupby(['id_driver']).agg(aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "entitled-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_boolean_columns(dataframe):\n",
    "    frame = dataframe.copy()\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Replacement (no new columns needed, just transform strings to 0 or 1)\n",
    "    frame['interested_in_drayage'] = label_encoder.fit_transform(frame.interested_in_drayage)\n",
    "    frame['port_qualified'] = label_encoder.fit_transform(frame.port_qualified)\n",
    "    frame['driver_with_twic'] = label_encoder.fit_transform(frame.driver_with_twic)\n",
    "    \n",
    "    # Create new columns with more appropriate names, delete the old columns\n",
    "    frame['self_owned'] = label_encoder.fit_transform(frame.dim_carrier_type)\n",
    "    frame['mobile_signup'] = np.logical_xor(label_encoder.fit_transform(frame.signup_source), 1).astype(int)\n",
    "    frame['has_route_preference'] = label_encoder.fit_transform(~frame.dim_preferred_lanes.isnull())\n",
    "    frame.drop(columns=['dim_carrier_type', 'signup_source', 'dim_preferred_lanes'], inplace=True)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "phantom-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_columns(dataframe):\n",
    "    frame = dataframe.copy()\n",
    "\n",
    "    # Encode various truck types\n",
    "    trucks = pd.get_dummies(frame.carrier_trucks)\n",
    "    trucks.columns = ['truck-' + c.replace('[', '').replace(']', '').replace('\"', '').replace(',', '').replace(' ', '-') for c in trucks.columns]\n",
    "    \n",
    "    # Encode the 7 different days of the week\n",
    "    weekdays = pd.get_dummies(frame.weekday)\n",
    "    weekdays.columns = [f'prefers-{x}'.lower() for x in weekdays.columns]\n",
    "    \n",
    "    # Drop the originals since they are no longer needed.\n",
    "    frame.drop(columns=['carrier_trucks', 'weekday'], inplace=True)\n",
    "    \n",
    "    # Concatenate various new frames with the original and return\n",
    "    result = pd.concat([frame, trucks, weekdays], axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "raising-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_numericals(dataframe, columns=None):    \n",
    "    scaler = StandardScaler()\n",
    "    frame = None\n",
    "    \n",
    "    if columns:\n",
    "        frame = dataframe[columns].copy()\n",
    "    else:\n",
    "        frame = dataframe.copy()\n",
    "    \n",
    "    x = scaler.fit_transform(frame)\n",
    "    scaled_df = pd.DataFrame(x)\n",
    "    scaled_df.columns = frame.columns\n",
    "\n",
    "    \n",
    "    if columns:\n",
    "        frame = dataframe.copy()\n",
    "        frame[columns] = scaled_df.values\n",
    "    else:\n",
    "        frame = scaled_df.copy()\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "challenging-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_numericals(dataframe, columns, strategy='most_frequent', testset=False):\n",
    "    frame = dataframe.copy()\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "    \n",
    "    for col in columns:\n",
    "        imp.fit(frame[f'{col}'].values.reshape(-1, 1))\n",
    "        frame[f'{col}'] = imp.transform(frame[f'{col}'].values.reshape(-1, 1))\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chicken-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels(dataframe, loads_percentile, most_recent_percentile):\n",
    "    label_encoder = LabelEncoder()\n",
    "    frame = dataframe.copy()\n",
    "    \n",
    "    labels = (frame.total_loads >= loads_percentile) & (frame.most_recent_load_date >= most_recent_percentile)\n",
    "    frame['label'] = label_encoder.fit_transform(labels)\n",
    "    frame.drop(columns=['total_loads', 'most_recent_load_date'], inplace=True)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "transparent-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(dataframe, aggregate=False, standardize=False, testdata=False):\n",
    "    frame = dataframe.copy()\n",
    "    scaler = StandardScaler()\n",
    "    loads_75th_percentile = 17\n",
    "    most_recent_75th_percentile = date(year=2021, month=2, day=10)\n",
    "\n",
    "\n",
    "    if testdata:\n",
    "        frame = convert_strings_to_dates(frame, testset=True)\n",
    "        frame = augment_boolean_columns(frame)\n",
    "        frame = encode_categorical_columns(frame)\n",
    "        frame = convert_date_to_int(frame, columns=['dt', 'ts_signup', 'first_load_date'])\n",
    "\n",
    "        # The only columns not in the new frame should be booleans that are safely set to 0\n",
    "        for col in dataframe.columns:\n",
    "            if col not in frame.columns:\n",
    "                frame[f'{col}'] = 0\n",
    "\n",
    "        frame.drop(columns=['weekday'], inplace=True)\n",
    "        frame = impute_numericals(frame, ['days_signup_to_approval'])\n",
    "\n",
    "        if standardize:\n",
    "            frame = standardize_numericals(frame)\n",
    "\n",
    "        frame.sort_index(axis=1, inplace=True)\n",
    "        return frame, None\n",
    "    \n",
    "    \n",
    "    frame = convert_strings_to_dates(frame)\n",
    "    \n",
    "    if aggregate:\n",
    "        frame = generate_labels(frame, loads_75th_percentile, most_recent_75th_percentile)\n",
    "        frame = aggregate_rows_by_driver_id(frame)\n",
    "        frame = augment_boolean_columns(frame)\n",
    "        frame = encode_categorical_columns(frame)\n",
    "        frame = convert_date_to_int(frame, columns=['dt', 'ts_signup', 'first_load_date'])\n",
    "\n",
    "        labels = frame.label.copy()\n",
    "        frame.drop(columns=['label'], inplace=True)\n",
    "        \n",
    "        if standardize:\n",
    "            frame = standardize_numericals(frame)\n",
    "\n",
    "        frame.sort_index(axis=1, inplace=True)\n",
    "        \n",
    "        return frame, labels\n",
    "    else:\n",
    "        frame = generate_labels(frame, loads_75th_percentile, most_recent_75th_percentile)\n",
    "        frame = augment_boolean_columns(frame)\n",
    "        frame = encode_categorical_columns(frame)\n",
    "        frame = convert_date_to_int(frame, columns=['dt', 'ts_signup', 'first_load_date'])\n",
    "\n",
    "        labels = frame.label.copy()\n",
    "        frame.drop(columns=['label'], inplace=True)\n",
    "        \n",
    "        if standardize:\n",
    "            frame = standardize_numericals(frame)\n",
    "\n",
    "        frame.sort_index(axis=1, inplace=True)\n",
    "        \n",
    "        return frame, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-ownership",
   "metadata": {},
   "source": [
    "## Load CSV to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "orange-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('training_dataset_V3.csv')\n",
    "test_df = pd.read_csv('score_V3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-jewel",
   "metadata": {},
   "source": [
    "**Drops duplicates and unwanted columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fatal-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Ids = train_df['Unnamed: 0']\n",
    "train_df.drop(columns=['Unnamed: 0', 'load_day', 'ts_first_approved', 'dim_carrier_company_name', 'home_base_city', 'home_base_state', 'id_carrier_number', 'year'], inplace=True)\n",
    "train_df.dropna(subset=['days_signup_to_approval', 'num_trucks'], inplace=True)\n",
    "\n",
    "test_Ids = test_df['Unnamed: 0']\n",
    "test_df.drop(columns=['Unnamed: 0', 'load_day', 'ts_first_approved', 'dim_carrier_company_name', 'home_base_city', 'home_base_state', 'id_carrier_number', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-choice",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1 - Generate Labels and 4 - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "subjective-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this when you want to generate output for Kaggle\n",
    "X_train, y_train = get_Xy(train_df, standardize=True, aggregate=False, testdata=False)\n",
    "X_test, _ = get_Xy(test_df, standardize=True, aggregate=False, testdata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continuous-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for training/testing your model\n",
    "X, y = get_Xy(train_df, standardize=True, aggregate=False, testdata=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cloudy-salon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56857, 40), (56857,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "built-sitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14215, 40), (14215,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-installation",
   "metadata": {},
   "source": [
    "# 3 - Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-cargo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "infinite-highway",
   "metadata": {},
   "source": [
    "# 5 - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-accreditation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-journal",
   "metadata": {},
   "source": [
    "# 6 - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-surveillance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "julian-mouth",
   "metadata": {},
   "source": [
    "# 7 - Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-swedish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "meaning-promise",
   "metadata": {},
   "source": [
    "# 8 - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-protection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "soviet-values",
   "metadata": {},
   "source": [
    "# 9 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-letter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "labeled-assault",
   "metadata": {},
   "source": [
    "# 10 - Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-willow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "painful-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866338374956032"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-fancy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
